{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "political-bracelet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-sauce",
   "metadata": {},
   "source": [
    "# Model deployment with Tensorflow Serving\n",
    "\n",
    "In this short notebook, we show how a model deployed with Tensorflow Serving can be used to predict the class of new instances using the server APIs. \n",
    "\n",
    "More information is available here,\n",
    "- https://github.com/tensorflow/serving\n",
    "- https://github.com/tensorflow/serving/blob/master/tensorflow_serving/g3doc/docker.md\n",
    "\n",
    "### How to deploy the model\n",
    "\n",
    "1) Save the trained model using `tf.saved_model.save`\n",
    "\n",
    "2) Get the git repo with the essential code for making a container using Docker\n",
    "\n",
    "`docker pull tensorflow/serving`\n",
    "\n",
    "3) Start the container with the pre-trained model\n",
    "\n",
    "docker run -p 8501:8501 --mount type=bind,source=/path/to/my_model/,target=/models/my_model -e MODEL_NAME=my_model -t tensorflow/serving\n",
    "\n",
    "NOTE: In the following, the model is called *cnn_classifier*.\n",
    "\n",
    "### Query the model\n",
    "\n",
    "We can now query the model using the following notebook,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "instructional-eleven",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"model_version_status\": [\n",
      "  {\n",
      "   \"version\": \"1\",\n",
      "   \"state\": \"AVAILABLE\",\n",
      "   \"status\": {\n",
      "    \"error_code\": \"OK\",\n",
      "    \"error_message\": \"\"\n",
      "   }\n",
      "  }\n",
      " ]\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check that the model is running,\n",
    "r = requests.get('http://localhost:8501/v1/models/cnn_classifier')\n",
    "\n",
    "print(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dirty-association",
   "metadata": {},
   "source": [
    "Load the dataset with the inputs values (used for getting predictions), and expected outputs,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fourth-moscow",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load('./datasets/vectorized/X_test.npy',allow_pickle=True)\n",
    "y_test = np.load('./datasets/vectorized/y_test.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-vietnamese",
   "metadata": {},
   "source": [
    "This function prepare each input for prediciton,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "voluntary-zoning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_input(X):\n",
    "    output = X.astype(np.float32).tolist()\n",
    "    return [el for el in output if el != 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formed-gilbert",
   "metadata": {},
   "source": [
    "In the following, we prepare the input in JSON format and we query the model with it. We get its response with an output value, and we check if the model is making good predictions or not (on this test set, it should have 85% accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "viral-merit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy is 0.85\n"
     ]
    }
   ],
   "source": [
    "N,_ = y_test.shape\n",
    "correct_pred = 0\n",
    "\n",
    "for x_instance,y_instance in zip(X_test,y_test):\n",
    "    \n",
    "    # Prepare input according to Tensorflow Serving APIs\n",
    "    input_data = {}\n",
    "    input_data[\"instances\"] = [to_input(x_instance)]\n",
    "    \n",
    "    # Need to be in json format\n",
    "    input_json = json.dumps(input_data)\n",
    "\n",
    "    # Send request to Tensorflow Serving server\n",
    "    r = requests.post('http://localhost:8501/v1/models/cnn_classifier:predict',\n",
    "                      data=input_json\n",
    "                     )\n",
    "\n",
    "    # Get output and process it\n",
    "    output = json.loads(r.text)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(output['error'])\n",
    "\n",
    "    # Check if predictions are correct\n",
    "    y_predict = np.argmax(output['predictions'])\n",
    "    y_expected = np.argmax(y_instance)\n",
    "    \n",
    "    if y_predict == y_expected:\n",
    "        correct_pred += 1\n",
    "        \n",
    "print('Model accuracy is {:.2f}'.format(correct_pred/N))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alone-crossing",
   "metadata": {},
   "source": [
    "The accuracy obtained is consistent with the one we computed previously. The model seems to have been correctly deployed.\n",
    "\n",
    "NOTE: from here it should not be so difficult to upload the model on the cloud (for example, using Amazon ECR and Lambda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:arxiv_env]",
   "language": "python",
   "name": "conda-env-arxiv_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
